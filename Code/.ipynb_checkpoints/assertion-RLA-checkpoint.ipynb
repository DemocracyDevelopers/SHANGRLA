{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion RLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the assertion audit tool\n",
    "\n",
    "The tool requires as input:\n",
    "\n",
    "+ audit-specific and contest-specific parameters, such as\n",
    "    - whether to sample with or without replacement\n",
    "    - the name of the risk function to use, and any parameters it requires\n",
    "    - a risk limit for each contest to be audited\n",
    "    - the social choice function for each contest, including the number of winners\n",
    "    - candidate identifiers\n",
    "+ a ballot manifest**\n",
    "+ a random seed\n",
    "+ a file of cast vote records\n",
    "+ reported results for each contest\n",
    "+ json files of assertions for IRV contests (one file per IRV contest)\n",
    "+ human reading of voter intent from the paper ballots selected for audit\n",
    "\n",
    "** The ballot manifest could be only for ballots purported to contain the\n",
    "contests under audit (manifest_type == \"STYLE\"), or could include ballots that might not contain the\n",
    "contest (manifest_type == \"ALL\"). These are treated differently. If the manifest lists only ballots purported\n",
    "to contain the contest under audit and a sampled ballot turns out not to\n",
    "contain the contest, that is considered a discrepancy, dealt with using the \"phantoms to zombies\" approach.\n",
    "\n",
    "The tool helps select ballots for audit, and reports when the audit has found sufficiently strong evidence to stop.\n",
    "\n",
    "The tool exports a log of all the audit inputs except the CVR file, but including the auditors' manually determined voter intent from the audited ballots.\n",
    "\n",
    "The current version uses a single sample to audit all contests. It would be possible to refine things to target smaller contests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters, write_audit_parameters\n",
    "from dominion_tools import \\\n",
    "    prep_dominion_manifest, sample_from_manifest, write_ballots_sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample \n",
    "* `replacement`: whether to sample with replacement. If the sample is drawn with replacement, gamma must also be specified.\n",
    "* `risk_function`: the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_martingale`. Not all risk functions work with every social choice function. `wald_sprt` applies only to plurality contests.\n",
    "* `g`: a parameter to hedge against the possibility of observing a maximum overstatement. Require $g \\in [0, 1)$ for `kaplan_markov` and `kaplan_wald`\n",
    "* `N_ballots`: an upper bound on the number of ballots cast in the contest. This should be derived independently of the voting system.\n",
    "\n",
    "----\n",
    "\n",
    "* `cvr_file`: filename for CVRs (input)\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `manifest_type`: \"STYLE\" if the manifest is supposed to list only ballots that contain the contests under audit; \"ALL\" if the manifest contains all ballots cast in the election\n",
    "* `assertion_file`: filename of assertions for IRV contests, in RAIRE format\n",
    "* `sample_file`: filename for sampled ballot identifiers (output)\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled ballots (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "\n",
    "----\n",
    "\n",
    "* `error_rates`: dict of expected error rates. The keys are\n",
    "    + `o1_rate`: expected rate of 1-vote overstatements. Recommended value $\\ge$ 0.001 if there are hand-marked ballots. Larger values increase the initial sample size, but make it more likely that the audit will conclude in a single round if the audit finds errors\n",
    "    + `o2_rate`: expected rate of 2-vote overstatements. Recommended value 0.\n",
    "    + `u1_rate`: expected rate of 1-vote understatements. Recommended value 0.\n",
    "    + `u2_rate`: expected rate of 2-vote understatements. Recommended value 0.\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are dicts with keys:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `ballots_cast`: an upper bound on the number of cast ballots that contain the contest\n",
    "        - `choice_function`: `plurality`, `supermajority`, or `IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV not supported; multi-winner super-majority is nonsense)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3.\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won. Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345678901234567890  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = True  # Sampling without replacement isn't implemented\n",
    "risk_function = \"kaplan_martingale\"\n",
    "g=0.1\n",
    "N_ballots = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_file = './Data/SFDA_2019_Nov8Partial.raire'\n",
    "manifest_file = './Data/ballot manifest-Sample.xlsx'\n",
    "manifest_type = 'STYLE'\n",
    "sample_file = './Data/sample.csv'\n",
    "mvr_file = './Data/mvr.json'\n",
    "log_file = './Data/log.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates = {'o1_rate':0.002,      # expect 2 1-vote overstatements per 1000 ballots in the CVR stratum\n",
    "               'o2_rate':0,          # expect 0 2-vote overstatements\n",
    "               'u1_rate':0,          # expect 0 1-vote understatements\n",
    "               'u2_rate':0}          # expect 0 2-vote understatements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit. Contest 339 is the DA race\n",
    "contests = {'339':{'risk_limit':0.05,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['15','16','17','18','45'],\n",
    "                     'reported_winners' : ['15'],\n",
    "                     'assertion_file' : './Data/SF2019Nov8Assertions.json'\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of other social choice functions:\n",
    "\n",
    "> contests =  {'city_council':{'risk_limit':0.05,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':3,\n",
    "                     'candidates':['Doug','Emily','Frank','Gail','Harry'],\n",
    "                     'reported_winners' : ['Doug', 'Emily', 'Frank']\n",
    "                    },\n",
    "            'measure_1':{'risk_limit':0.05,\n",
    "                     'choice_function':'supermajority',\n",
    "                     'share_to_win':2/3,\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['yes','no'],\n",
    "                     'reported_winners' : ['yes']\n",
    "                    }                  \n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find audit parameters and conduct audit\n",
    "\n",
    "* For each contest:\n",
    "    - find claimed outcome by applying SCF to CVRs\n",
    "    - complain if claimed outcome disagrees with reported outcome\n",
    "    - construct assertions that imply contest outcome is correct\n",
    "    - for each assertion:\n",
    "        + find generalized diluted margin\n",
    "        \n",
    "* Find initial (incremental) sample size from smallest diluted margin, for the sampling plan\n",
    "    - Complain if expected error rates imply any assertion is incorrect\n",
    "\n",
    "* For each assertion:\n",
    "    - Initialize discrepancy counts to zero (o1, o2, u1, u2)\n",
    "    - Initialize measured risk to 1\n",
    "* While measured risk for any assertion exceeds its risk limit:\n",
    "    - expand sample by estimated increment\n",
    "        + identify ballots in manifest\n",
    "        + update the log file with incremental sample\n",
    "    - import audit results when ballots have been audited\n",
    "    - for each assertion:\n",
    "        + for each sampled ballot:\n",
    "            - increment discrepancy count for the assertion\n",
    "        + find measured risk\n",
    "    - update log file with new measured risks\n",
    "    - if any measured risk exceeds its risk limit:\n",
    "        + estimate incremental sample required to complete the audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'339': {'18 v 17 elim 15 16 45': <assertion_audit_utils.Assertion at 0x110de4358>,\n",
       "  '17 v 16 elim 15 18 45': <assertion_audit_utils.Assertion at 0x110de4470>,\n",
       "  '15 v 18 elim 16 17 45': <assertion_audit_utils.Assertion at 0x110de4390>,\n",
       "  '18 v 16 elim 15 17 45': <assertion_audit_utils.Assertion at 0x110de43c8>,\n",
       "  '17 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x110de4160>,\n",
       "  '15 v 17 elim 16 45': <assertion_audit_utils.Assertion at 0x110de42b0>,\n",
       "  '15 v 17 elim 16 18 45': <assertion_audit_utils.Assertion at 0x110de4208>,\n",
       "  '18 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x110de41d0>,\n",
       "  '15 v 16 elim 17 45': <assertion_audit_utils.Assertion at 0x110de4048>,\n",
       "  '15 v 16 elim 17 18 45': <assertion_audit_utils.Assertion at 0x110de40b8>,\n",
       "  '15 v 16 elim 18 45': <assertion_audit_utils.Assertion at 0x110de45f8>,\n",
       "  '15 v 16 elim 45': <assertion_audit_utils.Assertion at 0x110de4a20>,\n",
       "  '15 v 45': <assertion_audit_utils.Assertion at 0x110de49b0>}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the ballot manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stark/Dropbox/Letters/Ms/Vote/Assertion19/Code/dominion_tools.py:28: UserWarning: Manifest does not account for every ballot cast; adding a phantom batch\n",
      "  warnings.warn('Manifest does not account for every ballot cast; adding a phantom batch')\n"
     ]
    }
   ],
   "source": [
    "# special for SF/Dominion manifest format\n",
    "manifest = pd.read_excel(manifest_file)\n",
    "manifest, manifest_ballots = prep_dominion_manifest(manifest, N_ballots)\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CVRs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 118151 rows\n"
     ]
    }
   ],
   "source": [
    "cvr_input = []\n",
    "with open(cvr_file) as f:\n",
    "    cvr_reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for row in cvr_reader:\n",
    "        cvr_input.append(row)\n",
    "\n",
    "print(\"Read {} rows\".format(len(cvr_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CVRs\n",
    "cvr_list = CVR.from_raire(cvr_input)\n",
    "print(\"After merging, there are CVRs for {} ballots\".format(len(cvr_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging, there are CVRs for 118149 ballots\n"
     ]
    }
   ],
   "source": [
    "# Create CVRs for phantom ballots\n",
    "n_phantoms = N_ballots - manifest_ballots\n",
    "for i in range(n_phantoms):\n",
    "    cvr_list.append(CVR(id='phantom-'+str(i+1), votes={}))\n",
    "\n",
    "len(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum assorter mean 0.5070715791077368\n"
     ]
    }
   ],
   "source": [
    "# find the mean of the assorters for the CVRs and check whether the assertions are met\n",
    "assorter_means = {}\n",
    "min_mean = np.infty\n",
    "for c in contests.keys():\n",
    "    contests[c]['cvr_means'] = {}\n",
    "    for asrtn in all_assertions[c]:\n",
    "        # find mean of the assertion for the CVRs\n",
    "        amean = all_assertions[c][asrtn].assorter_mean(cvr_list)\n",
    "        if amean < 1/2:\n",
    "            warn(\"assertion {} not satisfied by CVRs: mean value is {}\".format(asrtn, amean))\n",
    "        contests[c]['cvr_means'][asrtn] = amean\n",
    "        min_mean = np.min([min_mean, amean])\n",
    "\n",
    "print(\"minimum assorter mean {}\".format(min_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'339': {'risk_limit': 0.05,\n",
       "  'choice_function': 'IRV',\n",
       "  'n_winners': 1,\n",
       "  'candidates': ['15', '16', '17', '18', '45'],\n",
       "  'reported_winners': ['15'],\n",
       "  'assertion_file': './Data/SF2019Nov8Assertions.json',\n",
       "  'assertion_json': [{'winner': '18',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['15', '16', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 17]'},\n",
       "   {'winner': '17',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 17 16]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '18',\n",
       "    'already_eliminated': ['16', '17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 18]'},\n",
       "   {'winner': '18',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 16]'},\n",
       "   {'winner': '17',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 17 16 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['16', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 17 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['16', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 17]'},\n",
       "   {'winner': '18',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 16 17]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['17', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 17]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 17 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '45',\n",
       "    'already_eliminated': '',\n",
       "    'assertion_type': 'WINNER_ONLY',\n",
       "    'explanation': 'Rules out case where 15 is eliminated before 45'}],\n",
       "  'cvr_means': {'18 v 17 elim 15 16 45': 0.5070715791077368,\n",
       "   '17 v 16 elim 15 18 45': 0.5128312554486284,\n",
       "   '15 v 18 elim 16 17 45': 0.5229032831424726,\n",
       "   '18 v 16 elim 15 17 45': 0.5275245664372953,\n",
       "   '17 v 16 elim 15 45': 0.5307831636323626,\n",
       "   '15 v 17 elim 16 45': 0.5346553927667607,\n",
       "   '15 v 17 elim 16 18 45': 0.5472835148837485,\n",
       "   '18 v 16 elim 15 45': 0.561422441154813,\n",
       "   '15 v 16 elim 17 45': 0.5639192883562282,\n",
       "   '15 v 16 elim 17 18 45': 0.5636357480808132,\n",
       "   '15 v 16 elim 18 45': 0.5796875132248263,\n",
       "   '15 v 16 elim 45': 0.5756840938137436,\n",
       "   '15 v 45': 0.6483550432081524}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, error_rates, contests)\n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_ballots, error_rates, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate initial sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find initial sample size\n",
    "initial_size = 100 # FIX ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample includes 100 phantom ballots, which will be treated conservatively.\n"
     ]
    }
   ],
   "source": [
    "# draw the initial sample\n",
    "prng = SHA256(seed)\n",
    "sample = sample_by_index(N_ballots, initial_size, prng=prng) # 1-indexed\n",
    "phantoms = np.sum(sample > manifest_ballots)\n",
    "print(\"The sample includes {} phantom ballots, which will be treated conservatively.\".format(phantoms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up the sampled ballots in the manifest\n",
    "sample_ballots = sample_from_manifest(manifest, sample)\n",
    "\n",
    "# write the sample\n",
    "write_ballots_sampled(sample_file, sample_ballots, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the audited sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99808-81-1 {'333': {'15': 1, '16': 2, '17': 3, '18': 4}}\n",
      "99808-81-2 {'333': {'15': 1}}\n",
      "99808-81-3 {'333': {}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(mvr[i].id, mvr[i].votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Phantoms/Zombies\n",
    "\n",
    "Given an independent (i.e., not relying on the voting system) upper bound on the number of sheets that contain the contest, if the number of CVRs that contain the contest does not exceed that bound, we can sample from paper purported to contain the contest and use the \"zombies\" approach (Banuelos & Stark) to deal with missing CVRs. This can greatly increase the efficiency of the audit if the contest is on only a small percentage of the ballots.\n",
    "\n",
    "Any sampled phantom sheet (i.e., a sheet for which there are no CVRs) is treated as if its CVR is a non-vote (which it is), and as if its MVR was least favorable (a \"zombie\" producing the greatest doubt in every assertion, separately). Any sampled sheet for which\n",
    "there is a CVR is compared to its corresponding CVR. \n",
    "If the sheet turns out not to contain the contest (despite the fact that the CVR says it does), the MVR is treated in the least favorable way for each assertion (i.e., as a zombie rather than as a non-vote)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust for phantoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify assertions not yet confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalation: how many more ballots should be drawn?\n",
    "\n",
    "This tool estimates how many more ballots will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* ballots already sampled\n",
    "* assumption that we will continue to see overstatements and understatements at the same rate that observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes_new = {}\n",
    "\n",
    "# TBD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the sample\n",
    "# reset the seed\n",
    "prng = SHA256(seed)\n",
    "old_sample = sample\n",
    "sample = sample_by_index(N_ballots, sample_size, prng=prng)\n",
    "incremental_sample = np.sort(list(set(sample) - set(old_sample)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^n (1 - \\omega_i/v) = \\frac{1}{N} \\left ( N - (1/v) \\sum_{i=1}^N \\omega_i \\right )\n",
    "$$\n",
    "\n",
    "$$\n",
    " = 1 - \\bar{\\omega}/v\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {
    "6cab9cab294247839758fa9e8d64d122": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "b7b0321f834d45ebb1bdc036fba7a916": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
