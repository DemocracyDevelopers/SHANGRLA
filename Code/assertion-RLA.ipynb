{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion RLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the assertion audit tool\n",
    "\n",
    "The tool requires as input:\n",
    "\n",
    "+ audit-specific and contest-specific parameters, such as\n",
    "    - whether to sample with or without replacement\n",
    "    - the name of the risk function to use, and any parameters it requires\n",
    "    - a risk limit for each contest to be audited\n",
    "    - the social choice function for each contest, including the number of winners\n",
    "    - candidate identifiers\n",
    "+ a ballot manifest\n",
    "+ a random seed\n",
    "+ a file of cast vote records\n",
    "+ reported results for each contest\n",
    "+ json files of assertions for IRV contests (one file per IRV contest)\n",
    "+ human reading of voter intent from the paper ballots selected for audit\n",
    "\n",
    "The tool helps select ballots for audit, and reports when the audit has found sufficiently strong evidence to stop.\n",
    "\n",
    "The tool exports a log of all the audit inputs except the CVR file, but including the auditors' manually determined voter intent from the audited ballots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean,\\\n",
    "    check_audit_parameters, write_audit_parameters\n",
    "from dominion_tools import \\\n",
    "    prep_dominion_manifest, write_ballots_sampled,\\\n",
    "    read_dominion_cvrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample \n",
    "* `replacement`: whether to sample with replacement. If the sample is drawn with replacement, gamma must also be specified.\n",
    "* `risk_function`: the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_martingale`. Not all risk functions work with every social choice function. `wald_sprt` applies only to plurality contests.\n",
    "* `g`: a parameter to hedge against the possibility of observing a maximum overstatement. Require $g \\in [0, 1)$ for `kaplan_markov` and `kaplan_wald`\n",
    "* `N_ballots`: an upper bound on the number of ballots cast in the contest. This should be derived independently of the voting system.\n",
    "\n",
    "----\n",
    "\n",
    "* `cvr_file`: filename for CVRs (input)\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `assertion_file`: filename of assertions for IRV contests, in RAIRE format\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled ballots (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "\n",
    "----\n",
    "\n",
    "* `error_rates`: dict of expected error rates. The keys are\n",
    "    + `o1_rate`: expected rate of 1-vote overstatements. Recommended value $\\ge$ 0.001 if there are hand-marked ballots. Larger values increase the initial sample size, but make it more likely that the audit will conclude in a single round if the audit finds errors\n",
    "    + `o2_rate`: expected rate of 2-vote overstatements. Recommended value 0.\n",
    "    + `u1_rate`: expected rate of 1-vote understatements. Recommended value 0.\n",
    "    + `u2_rate`: expected rate of 2-vote understatements. Recommended value 0.\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are dicts with keys:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `ballots_cast`: an upper bound on the number of cast ballots that contain the contest\n",
    "        - `choice_function`: `plurality`, `supermajority`, or `IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV not supported; multi-winner super-majority is nonsense)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3.\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won. Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345678901234567890  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = True  # Sampling without replacement isn't implemented\n",
    "risk_function = \"kaplan_martingale\"\n",
    "g=0.1\n",
    "N_ballots = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_file = './Data/CvrExport.json'\n",
    "manifest_file = './Data/ballot manifest-Sample.xlsx'\n",
    "mvr_file = './Data/mvr.csv'\n",
    "log_file = './Data/log.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates = {'o1_rate':0.002,      # expect 2 1-vote overstatements per 1000 ballots in the CVR stratum\n",
    "               'o2_rate':0,          # expect 0 2-vote overstatements\n",
    "               'u1_rate':0,          # expect 0 1-vote understatements\n",
    "               'u2_rate':0}          # expect 0 2-vote understatements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit\n",
    "contests = {'mayor':{'risk_limit':0.05,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['Alice','Bob','Cindy'],\n",
    "                     'reported_winners' : ['Alice'],\n",
    "                     'assertion_file' : './Data/SF2019Nov8Assertions.json'\n",
    "                    }\n",
    "           }\n",
    "\"\"\"            'city_council':{'risk_limit':0.05,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':3,\n",
    "                     'candidates':['Doug','Emily','Frank','Gail','Harry'],\n",
    "                     'reported_winners' : ['Doug', 'Emily', 'Frank']\n",
    "                    },\n",
    "            'measure_1':{'risk_limit':0.05,\n",
    "                     'choice_function':'supermajority',\n",
    "                     'share_to_win':2/3,\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['yes','no'],\n",
    "                     'reported_winners' : ['yes']\n",
    "                    }                  \n",
    "           }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, error_rates, contests)\n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_ballots, error_rates, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find audit parameters and conduct audit\n",
    "\n",
    "* For each contest:\n",
    "    - find claimed outcome by applying SCF to CVRs\n",
    "    - complain if claimed outcome disagrees with reported outcome\n",
    "    - construct assertions that imply contest outcome is correct\n",
    "    - for each assertion:\n",
    "        + find generalized diluted margin\n",
    "        \n",
    "* Find initial (incremental) sample size from smallest diluted margin, for the sampling plan\n",
    "    - Complain if expected error rates imply any assertion is incorrect\n",
    "\n",
    "* For each assertion:\n",
    "    - Initialize discrepancy counts to zero (o1, o2, u1, u2)\n",
    "    - Initialize measured risk to 1\n",
    "* While measured risk for any assertion exceeds its risk limit:\n",
    "    - expand sample by estimated increment\n",
    "        + identify ballots in manifest\n",
    "        + update the log file with incremental sample\n",
    "    - import audit results when ballots have been audited\n",
    "    - for each assertion:\n",
    "        + for each sampled ballot:\n",
    "            - increment discrepancy count for the assertion\n",
    "        + find measured risk\n",
    "    - update log file with new measured risks\n",
    "    - if any measured risk exceeds its risk limit:\n",
    "        + estimate incremental sample required to complete the audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mayor': {'18 v 17 elim 15 16 45': <assertion_audit_utils.Assertion at 0x11a0edc50>,\n",
       "  '17 v 16 elim 15 18 45': <assertion_audit_utils.Assertion at 0x11a0edac8>,\n",
       "  '15 v 18 elim 16 17 45': <assertion_audit_utils.Assertion at 0x11a0ed9e8>,\n",
       "  '18 v 16 elim 15 17 45': <assertion_audit_utils.Assertion at 0x11a0eda90>,\n",
       "  '17 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x11a0ed6d8>,\n",
       "  '15 v 17 elim 16 45': <assertion_audit_utils.Assertion at 0x11a0ed710>,\n",
       "  '15 v 17 elim 16 18 45': <assertion_audit_utils.Assertion at 0x11a0ed898>,\n",
       "  '18 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x11a0ed7b8>,\n",
       "  '15 v 16 elim 17 45': <assertion_audit_utils.Assertion at 0x11a0ed860>,\n",
       "  '15 v 16 elim 17 18 45': <assertion_audit_utils.Assertion at 0x11a0ed908>,\n",
       "  '15 v 16 elim 18 45': <assertion_audit_utils.Assertion at 0x11a0ed390>,\n",
       "  '15 v 16 elim 45': <assertion_audit_utils.Assertion at 0x11a0ed470>,\n",
       "  '15 v 45': <assertion_audit_utils.Assertion at 0x11a0ed550>},\n",
       " 'city_council': {'Doug v Gail': <assertion_audit_utils.Assertion at 0x11a0ed3c8>,\n",
       "  'Doug v Harry': <assertion_audit_utils.Assertion at 0x11a0ed240>,\n",
       "  'Emily v Gail': <assertion_audit_utils.Assertion at 0x11a0ede80>,\n",
       "  'Emily v Harry': <assertion_audit_utils.Assertion at 0x11a0edfd0>,\n",
       "  'Frank v Gail': <assertion_audit_utils.Assertion at 0x11a0e6198>,\n",
       "  'Frank v Harry': <assertion_audit_utils.Assertion at 0x11a0e6208>},\n",
       " 'measure_1': {'yes v all': <assertion_audit_utils.Assertion at 0x11a0ed5c0>}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CVRs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_list = read_dominion_cvrs(cvr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326538"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = []\n",
    "for c in cvr_list:\n",
    "    IDs.append(c.get_ID())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['99808_3_7',\n",
       " '99808_3_8',\n",
       " '99808_3_10',\n",
       " '99808_3_11',\n",
       " '99808_3_12',\n",
       " '99808_3_14',\n",
       " '99808_3_16',\n",
       " '99808_3_17',\n",
       " '99808_3_18',\n",
       " '99808_3_20',\n",
       " '99808_3_21',\n",
       " '99808_3_22',\n",
       " '99808_3_23',\n",
       " '99808_3_24',\n",
       " '99808_3_25',\n",
       " '99808_3_26',\n",
       " '99808_3_27',\n",
       " '99808_3_29',\n",
       " '99808_3_30',\n",
       " '99808_3_31']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs[2000:2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_list[0].get_votes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of the assorters for the CVRs and check whether the assertions are met\n",
    "assorter_means = {}\n",
    "for c in contests.keys():\n",
    "    contest[c]['cvr_means'] = {}\n",
    "    for asrtn in audit_assertions[c]:\n",
    "        # find mean of the assertion for the CVRs\n",
    "        amean = audit_assertions[c][asrtn].assorter.assorter_mean(cvrs)\n",
    "        if amean < 1/2:\n",
    "            warn(\"assertion \" + asrtn + \" not satisfied by CVRs: mean value is \" + amean)\n",
    "        contest[c]['cvr_means'][asrtn] = amean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the ballot manifest\n",
    "# special for SF manifest format\n",
    "manifest = pd.read_excel(manifest_file)\n",
    "prep_dominion_manifest(manifest, N_ballots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       76\n",
       "1      192\n",
       "2      308\n",
       "3      428\n",
       "4      543\n",
       "5      643\n",
       "6      761\n",
       "7      890\n",
       "8      994\n",
       "9     1091\n",
       "10    1142\n",
       "11    1272\n",
       "12    1393\n",
       "13    1516\n",
       "14    1639\n",
       "15    1732\n",
       "16    1814\n",
       "17    1904\n",
       "18    1996\n",
       "19    2100\n",
       "20    2189\n",
       "Name: cum_ballots, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest['cum_ballots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_manifest(parsed_manifest):\n",
    "    \"\"\"\n",
    "    Create a single ballot manifest with unique IDs for each ballot.\n",
    "    Identifiers are unique across batches, so the ballots can be considered\n",
    "    in a canonical order.\n",
    "    \"\"\"\n",
    "    second_manifest = {}\n",
    "    ballots_counted = 0\n",
    "    for batch in parsed_manifest.keys():\n",
    "        batch_size = len(parsed_manifest[batch])\n",
    "        second_manifest[batch] = list(range(ballots_counted + 1, \\\n",
    "                                    ballots_counted + batch_size + 1))\n",
    "        ballots_counted += batch_size\n",
    "    return second_manifest\n",
    "\n",
    "\n",
    "def find_ballot(ballot_num, unique_ballot_manifest):\n",
    "    \"\"\"\n",
    "    Find ballot among all the batches\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    ballot_num : int\n",
    "        a ballot number that was sampled\n",
    "    unique_ballot_manifest : dict\n",
    "        ballot manifest with unique IDs across batches\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple : (original_ballot_label, batch_label, which_ballot_in_batch)\n",
    "    \"\"\"\n",
    "    for batch, ballots in unique_ballot_manifest.items():\n",
    "        if ballot_num in ballots:\n",
    "            position = ballots.index(ballot_num) + 1\n",
    "            return (batch, position)\n",
    "    print(\"Ballot %i not found\" % ballot_num)\n",
    "    return None\n",
    "\n",
    "\n",
    "def sample_from_manifest(filename, sample, stratum_size):\n",
    "    \"\"\"\n",
    "    Sample from the ballot manifest\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    ballot_manifest = read_manifest_from_csv(filename)\n",
    "    manifest_parsed = parse_manifest(ballot_manifest)\n",
    "    listed = np.sum([len(v) for v in manifest_parsed.values()])\n",
    "    if listed != stratum_size:\n",
    "        print(\"WARNING: the number of ballots in the ballot manifest is \",\\\n",
    "              listed, \"but total number of reported votes is\", stratum_size)\n",
    "    \n",
    "    unique_ballot_manifest = unique_manifest(manifest_parsed)\n",
    "\n",
    "    ballots_sampled = []\n",
    "    m = np.zeros_like(sample, dtype=bool)\n",
    "    m[np.unique(sample, return_index=True)[1]] = True\n",
    "    for s in sample[m]:\n",
    "        batch_label, which_ballot = find_ballot(s, unique_ballot_manifest)\n",
    "        if s in sample[~m]:\n",
    "            ballots_sampled.append([s, batch_label, which_ballot, np.sum(np.array(sample) == s)])\n",
    "        else:\n",
    "            ballots_sampled.append([s, batch_label, which_ballot, 1])\n",
    "        \n",
    "    ballots_sampled.sort(key=lambda x: x[2]) # Sort second on order within batches\n",
    "    ballots_sampled.sort(key=lambda x: x[1]) # Sort first based on batch label\n",
    "    ballots_sampled.insert(0,[\"sampled ballot\", \"batch label\", \"which ballot in batch\", \"# times sampled\"])\n",
    "    return ballots_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the ballot manifest into a dict. keys are batches, values are ballot numbers.\n",
    "manifest_parsed = parse_manifest(ballot_manifest)\n",
    "\n",
    "# check whether manifest accounts for all CVRs and ballots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the manifest to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contest results\n",
    "for c in contests.keys():\n",
    "    contests[c]['winners'] = find_winners(contests[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign each ballot a unique ID\n",
    "unique_cvr_manifest = unique_manifest(cvr_manifest_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find initial sample size\n",
    "initial_size = 10 # FIX ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 78\n",
    "f = 41\n",
    "sdm = 4.87\n",
    "sdf = 6.21\n",
    "math.sqrt(((m-1)*sdm**2 + (f-1)*sdf**2)/(f+m-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the initial sample\n",
    "prng = SHA256(seed)\n",
    "sample = sample_by_index(N_ballots, initial_size, prng=prng)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up sample ballots\n",
    "\n",
    "cvr_sample = []\n",
    "for s in sample1:\n",
    "    original_ballot_label, batch_label, which_ballot = find_ballot(s, \\\n",
    "                                                                   unique_cvr_manifest, \\\n",
    "                                                                   cvr_manifest_parsed)\n",
    "    cvr_sample.append([s, batch_label, which_ballot])\n",
    "\n",
    "cvr_sample.sort(key=lambda x: x[2]) # Sort second on order within batches\n",
    "cvr_sample.sort(key=lambda x: x[1]) # Sort first based on batch label\n",
    "cvr_sample.insert(0,[\"sampled ballot\", \"batch label\", \"which ballot in batch\"])\n",
    "\n",
    "display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in cvr_sample)\n",
    "        )\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find audit p-values across assertions\n",
    "def kaplan_wald(sample, t=1/2, g = 0, random_order = True):\n",
    "    \"\"\"\n",
    "    Kaplan-Wald p-value for the hypothesis that the sample is drawn IID from a nonnegative\n",
    "    population with mean t against the alternative that the population mean is less than t.\n",
    "    \n",
    "    \"Pads\" the values by g to protect against an observation of 0.\n",
    "    \"\"\"\n",
    "    s = np.array(sample)\n",
    "    return np.min([1, np.min(np.cumprod((t+g)/(s+g))) if random_order else np.prod((t+g)/(s+g))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [1, 1, 1, 1, 1, 0, 0, 0]\n",
    "kaplan_wald(sample, g=0.01, random_order = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify assertions not yet confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalation: how many more ballots should be drawn?\n",
    "\n",
    "This tool estimates how many more ballots will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* ballots already sampled\n",
    "* assumption that we will continue to see overstatements and understatements at the same rate that observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes_new = {}\n",
    "\n",
    "# TBD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {
    "6cab9cab294247839758fa9e8d64d122": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "b7b0321f834d45ebb1bdc036fba7a916": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
