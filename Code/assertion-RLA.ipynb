{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion RLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the assertion audit tool\n",
    "\n",
    "The tool requires as input:\n",
    "\n",
    "+ audit-specific and contest-specific parameters, such as\n",
    "    - whether to sample with or without replacement\n",
    "    - the name of the risk function to use, and any parameters it requires\n",
    "    - a risk limit for each contest to be audited\n",
    "    - the social choice function for each contest, including the number of winners\n",
    "    - candidate identifiers\n",
    "+ a ballot manifest**\n",
    "+ a random seed\n",
    "+ a file of cast vote records\n",
    "+ reported results for each contest\n",
    "+ json files of assertions for IRV contests (one file per IRV contest)\n",
    "+ human reading of voter intent from the paper cards selected for audit\n",
    "\n",
    "** The ballot manifest could be only for cards purported to contain the\n",
    "contests under audit (manifest_type == \"STYLE\"), or could include cards that might not contain the\n",
    "contest (manifest_type == \"ALL\"). These are treated differently. If the sample is to be drawn only from cards that--according to the CVR--contain the contest, and a sampled card turns out not to\n",
    "contain the contest, that is considered a discrepancy, dealt with using the \"phantoms to zombies\" approach.\n",
    "It is assumed that every CVR corresponds to a card in the manifest, but there might\n",
    "be cards cast in the contest for which there is no corresponding CVR. In that case,\n",
    "phantom records are created to ensure that the audit is still truly risk-limiting.\n",
    "\n",
    "Given an independent (i.e., not relying on the voting system) upper bound on the number of cards that contain the contest, if the number of CVRs that contain the contest does not exceed that bound, we can sample from paper purported to contain the contest and use the \"zombies\" approach (Banuelos & Stark) to deal with missing CVRs. This can greatly increase the efficiency of the audit if the contest is on only a small percentage of the cast cards.\n",
    "\n",
    "Any sampled phantom card (i.e., a card for which there are no CVRs) is treated as if its CVR is a non-vote (which it is), and as if its MVR was least favorable (a \"zombie\" producing the greatest doubt in every assertion, separately). Any sampled card for which\n",
    "there is a CVR is compared to its corresponding CVR. \n",
    "If the card turns out not to contain the contest (despite the fact that the CVR says it does), the MVR is treated in the least favorable way for each assertion (i.e., as a zombie rather than as a non-vote).\n",
    "\n",
    "The tool helps select cards for audit, and reports when the audit has found sufficiently strong evidence to stop.\n",
    "\n",
    "The tool exports a log of all the audit inputs except the CVR file, but including the auditors' manually determined voter intent from the audited cards.\n",
    "\n",
    "The current version uses a single sample to audit all contests. It is possible to refine things to target smaller contests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters, find_margins,\\\n",
    "    find_p_values, find_sample_size, new_sample_size, prep_sample, summarize_status,\\\n",
    "    write_audit_parameters\n",
    "from dominion_tools import \\\n",
    "    prep_dominion_manifest, sample_from_cvr, write_cards_sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample \n",
    "* `replacement`: whether to sample with replacement. If the sample is drawn with replacement, gamma must also be specified.\n",
    "* `risk_function`: the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_martingale`. Not all risk functions work with every social choice function. `wald_sprt` applies only to plurality contests.\n",
    "* `g`: a parameter to hedge against the possibility of observing a maximum overstatement. Require $g \\in [0, 1)$ for `kaplan_markov` and `kaplan_wald`\n",
    "* `N_cards`: an upper bound on the number of pieces of paper cast in the contest. This should be derived independently of the voting system. A ballot consists of one or more cards.\n",
    "\n",
    "----\n",
    "\n",
    "* `cvr_file`: filename for CVRs (input)\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `manifest_type`: \"STYLE\" if the manifest is supposed to list only cards that contain the contests under audit; \"ALL\" if the manifest contains all cards cast in the election\n",
    "* `assertion_file`: filename of assertions for IRV contests, in RAIRE format\n",
    "* `sample_file`: filename for sampled card identifiers (output)\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled cards (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "\n",
    "----\n",
    "\n",
    "* `error_rate`: expected rate of 1-vote overstatements. Recommended value $\\ge$ 0.001 if there are hand-marked ballots. Larger values increase the initial sample size, but make it more likely that the audit will conclude in a single round if the audit finds errors\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are dicts with keys:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `cards_cast`: an upper bound on the number of cast cards that contain the contest\n",
    "        - `choice_function`: `plurality`, `supermajority`, or `IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV not supported; multi-winner super-majority is nonsense)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3.\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won. Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 93686630803205229070  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = False\n",
    "risk_function = \"kaplan_martingale\"\n",
    "risk_fn = lambda x: TestNonnegMean.kaplan_martingale(x, N_cards)[0]\n",
    "g=0.1\n",
    "N_cards = 146662 # VBM turnout per SF Elections release 12\n",
    "        # https://sfelections.sfgov.org/november-5-2019-election-results-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_file = './Data/SFDA2019_PrelimReport12VBMJustDASheets.raire'\n",
    "manifest_file = './Data/N19 ballot manifest with WH location for RLA Upload VBM 11-14.xlsx'\n",
    "manifest_type = 'STYLE'\n",
    "sample_file = './Data/sample.csv'\n",
    "mvr_file = './Data/mvr.json'\n",
    "log_file = './Data/log.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = 0.002      # expect 2 1-vote overstatements per 1000 ballots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit. Contest 339 is the DA race\n",
    "contests = {'339':{'risk_limit':0.05,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     # VT: If I understand rightly we're ignoring 45, which is the write-in candiate.\n",
    "                     #'candidates':['15','16','17','18','45'],\n",
    "                     'candidates':['15','16','17','18'],\n",
    "                     'reported_winners' : ['15'],\n",
    "                     'assertion_file' : './Data/SFDA2019_PrelimReport12VBMJustDASheetsAgap0.05Assertions.json'\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of other social choice functions:\n",
    "\n",
    "> contests =  {'city_council':{'risk_limit':0.05,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':3,\n",
    "                     'candidates':['Doug','Emily','Frank','Gail','Harry'],\n",
    "                     'reported_winners' : ['Doug', 'Emily', 'Frank']\n",
    "                    },\n",
    "            'measure_1':{'risk_limit':0.05,\n",
    "                     'choice_function':'supermajority',\n",
    "                     'share_to_win':2/3,\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['yes','no'],\n",
    "                     'reported_winners' : ['yes']\n",
    "                    }                  \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'339': {'15 v 16': <assertion_audit_utils.Assertion at 0x7f45ad41f550>,\n",
       "  '15 v 18 elim 16 17': <assertion_audit_utils.Assertion at 0x7f45ad41f898>,\n",
       "  '18 v 17 elim 15 16': <assertion_audit_utils.Assertion at 0x7f45ad41f438>,\n",
       "  '15 v 17 elim 16': <assertion_audit_utils.Assertion at 0x7f45ad41f0f0>,\n",
       "  '15 v 17 elim 16 18': <assertion_audit_utils.Assertion at 0x7f45ad41f860>}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the ballot manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special for SF/Dominion manifest format\n",
    "manifest = pd.read_excel(manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CVRs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 146664 rows\n"
     ]
    }
   ],
   "source": [
    "cvr_input = []\n",
    "with open(cvr_file) as f:\n",
    "    cvr_reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for row in cvr_reader:\n",
    "        cvr_input.append(row)\n",
    "\n",
    "print(\"Read {} rows\".format(len(cvr_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging, there are CVRs for 146662 cards\n"
     ]
    }
   ],
   "source": [
    "# Import CVRs\n",
    "cvr_list = CVR.from_raire(cvr_input)\n",
    "print(\"After merging, there are CVRs for {} cards\".format(len(cvr_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn RAIRE-style identifiers into SF-style by substituting \"-\" for \"_\"\n",
    "for c in cvr_list:\n",
    "    c.set_id(str(c.id).replace(\"_\",\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 99813-1-1 votes: {'339': {'17': 1}} phantom: False\n",
      "id: 99813-1-3 votes: {'339': {'16': 1}} phantom: False\n",
      "id: 99813-1-6 votes: {'339': {'18': 1, '17': 2, '15': 3, '16': 4}} phantom: False\n",
      "id: 99813-1-8 votes: {'339': {'18': 1}} phantom: False\n",
      "id: 99813-1-9 votes: {'339': {'': 1}} phantom: False\n",
      "id: 99813-1-11 votes: {'339': {'16': 1, '17': 2, '15': 3, '18': 4}} phantom: False\n",
      "id: 99813-1-13 votes: {'339': {'15': 1, '16': 2, '17': 3, '18': 4}} phantom: False\n",
      "id: 99813-1-16 votes: {'339': {'15': 1}} phantom: False\n",
      "id: 99813-1-17 votes: {'339': {'15': 1}} phantom: False\n",
      "id: 99813-1-19 votes: {'339': {'16': 1}} phantom: False\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(str(cvr_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tray #</th>\n",
       "      <th>Tabulator Number</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Total Ballots</th>\n",
       "      <th>VBMCart.Cart number</th>\n",
       "      <th>cum_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>78</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>77</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>79</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>80</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>292557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5477</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>84</td>\n",
       "      <td>222</td>\n",
       "      <td>19</td>\n",
       "      <td>292779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5478</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>83</td>\n",
       "      <td>346</td>\n",
       "      <td>19</td>\n",
       "      <td>293125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>82</td>\n",
       "      <td>332</td>\n",
       "      <td>19</td>\n",
       "      <td>293457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5480</th>\n",
       "      <td>3507</td>\n",
       "      <td>99802</td>\n",
       "      <td>822</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>293555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5481 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tray # Tabulator Number Batch Number  Total Ballots VBMCart.Cart number  \\\n",
       "0         1            99808           78            116                   3   \n",
       "1         1            99808           77            115                   3   \n",
       "2         1            99808           79            120                   3   \n",
       "3         1            99808           81             76                   3   \n",
       "4         1            99808           80            116                   3   \n",
       "...     ...              ...          ...            ...                 ...   \n",
       "5476   3506            99815           86              2                  19   \n",
       "5477   3506            99815           84            222                  19   \n",
       "5478   3506            99815           83            346                  19   \n",
       "5479   3506            99815           82            332                  19   \n",
       "5480   3507            99802          822             98                  14   \n",
       "\n",
       "      cum_cards  \n",
       "0           116  \n",
       "1           231  \n",
       "2           351  \n",
       "3           427  \n",
       "4           543  \n",
       "...         ...  \n",
       "5476     292557  \n",
       "5477     292779  \n",
       "5478     293125  \n",
       "5479     293457  \n",
       "5480     293555  \n",
       "\n",
       "[5481 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there is a CVR for every card cast in the contest. If not, add phantoms.\n",
    "\n",
    "n_cvrs = len(cvr_list)\n",
    "manifest, manifest_cards, phantom_cards = prep_dominion_manifest(manifest, N_cards, n_cvrs)\n",
    "\n",
    "manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 0 phantom records\n"
     ]
    }
   ],
   "source": [
    "# Create CVRs and MVRs for phantom cards\n",
    "# If the sample draws a phantom card, these CVRs will be used in the comparison.\n",
    "# phantom MVRs should be treated as zeros by the Assorter for every contest\n",
    "phantom_vrs = []\n",
    "for i in range(phantom_cards):\n",
    "    phantom_vrs.append(CVR(id='phantom-1-'+str(i+1), votes={}, phantom = True))  # matches expected RAIRE id for parsing later\n",
    "    \n",
    "cvr_list = cvr_list + phantom_vrs\n",
    "\n",
    "print(\"Created {} phantom records\".format(len(phantom_vrs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293555"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum assorter margin 0.0015614133176964362\n",
      "margins in contest 339\n",
      "15 v 16 0.0015614133176964362\n",
      "15 v 18 elim 16 17 0.028923647570604505\n",
      "18 v 17 elim 15 16 0.045792366120740224\n",
      "15 v 17 elim 16 0.08064120222007065\n",
      "15 v 17 elim 16 18 0.10951712099930444\n"
     ]
    }
   ],
   "source": [
    "# find the mean of the assorters for the CVRs and check whether the assertions are met\n",
    "min_margin = find_margins(contests, all_assertions, cvr_list)\n",
    "\n",
    "print(\"minimum assorter margin {}\".format(min_margin))\n",
    "for c in contests:\n",
    "    print(\"margins in contest {}\".format(c))\n",
    "    for a, m in contests[c]['margins'].items():\n",
    "        print(a, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, error_rate, contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_cards, n_cvrs, \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find initial sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find initial sample size\n",
    "ss_fn = lambda m, r: TestNonnegMean.kaplan_martingale_sample_size(N_cards, m,\\\n",
    "                    error_rate = 0.001, alpha=r)\n",
    "sample_size = find_sample_size(contests, all_assertions, sample_size_function = ss_fn)\n",
    "sample_size\n",
    "\n",
    "sample_size = 200\n",
    "sample_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample includes 0 phantom cards.\n"
     ]
    }
   ],
   "source": [
    "# draw the initial sample\n",
    "prng = SHA256(seed)\n",
    "sample = sample_by_index(N_cards, sample_size, prng=prng) # 1-indexed\n",
    "n_phantom_sample = np.sum([cvr_list[i].phantom for i in sample])\n",
    "print(\"The sample includes {} phantom cards.\".format(n_phantom_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_sample_lookup, cvr_sample, mvr_phantoms_sample = sample_from_cvr(cvr_list, manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the sample\n",
    "write_cards_sampled(sample_file, cvr_sample_lookup, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the audited sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MVRs for phantoms\n",
    "mvr_sample = mvr_sample + mvr_phantoms_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'99808-81-1' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3dd82bc0a2b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprep_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvr_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvr_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m p_max = find_p_values(contests, all_assertions, mvr_sample, cvr_sample, manifest_type, \\\n\u001b[1;32m      3\u001b[0m                       risk_function= risk_fn)\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maximum assertion p-value {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_assertions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/shared/Code/assertion_audit_utils.py\u001b[0m in \u001b[0;36mprep_sample\u001b[0;34m(mvr_sample, cvr_sample)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \"\"\"\n\u001b[1;32m   1271\u001b[0m     \u001b[0mid_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvr_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m     \u001b[0mmvr_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mid_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvr_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvr_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/shared/Code/assertion_audit_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \"\"\"\n\u001b[1;32m   1271\u001b[0m     \u001b[0mid_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvr_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m     \u001b[0mmvr_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mid_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvr_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvr_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: '99808-81-1' is not in list"
     ]
    }
   ],
   "source": [
    "prep_sample(mvr_sample, cvr_sample)\n",
    "p_max = find_p_values(contests, all_assertions, mvr_sample, cvr_sample, manifest_type, \\\n",
    "                      risk_function= risk_fn)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_cards, n_cvrs, \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many more cards should be audited?\n",
    "\n",
    "Estimate how many more cards will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* cards already sampled\n",
    "* the assumption that we will continue to see errors at the same rate observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_by_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-979c422fbf37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m new_size = new_sample_size(contests, all_assertions, mvr_sample, cvr_sample, manifest_type,\\\n\u001b[0;32m----> 2\u001b[0;31m             risk_function= lambda x: TestNonnegMean.kaplan_martingale(x, N_cards)[0])\n\u001b[0m",
      "\u001b[0;32m/opt/shared/Code/assertion_audit_utils.py\u001b[0m in \u001b[0;36mnew_sample_size\u001b[0;34m(contests, assertions, mvr_sample, cvr_sample, manifest_type, risk_function)\u001b[0m\n\u001b[1;32m   1316\u001b[0m                      a.margin, manifest_type=manifest_type) for i in range(len(mvr_sample))]\n\u001b[1;32m   1317\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcontests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk_limit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m                     \u001b[0mone_more\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m                     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone_more\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrisk_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_by_index' is not defined"
     ]
    }
   ],
   "source": [
    "new_size = new_sample_size(contests, all_assertions, mvr_sample, cvr_sample, manifest_type,\\\n",
    "            risk_function= lambda x: TestNonnegMean.kaplan_martingale(x, N_cards)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the sample\n",
    "# reset the seed\n",
    "prng = SHA256(seed)\n",
    "old_sample = sample\n",
    "sample = sample_by_index(N_cards, new_size, prng=prng)\n",
    "incremental_sample = np.sort(list(set(sample) - set(old_sample)))\n",
    "n_phantom_sample = np.sum([cvr_list[i].phantom for i in incremental_sample])\n",
    "print(\"The incremental sample includes {} phantom cards.\".format(n_phantom_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_sample_lookup_new, cvr_sample_new, mvr_phantoms_sample_new = \\\n",
    "                sample_from_cvr(cvr_list, manifest, incremental_sample)\n",
    "write_cards_sampled(sample_file, cvr_sample_lookup_new, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvr_json should contain the complete set of mvrs, including those in previous rounds\n",
    "\n",
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile entire sample\n",
    "cvr_sample_lookup, cvr_sample, mvr_phantoms_sample = sample_from_cvr(cvr_list, manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MVRs for phantoms\n",
    "mvr_sample = mvr_sample + mvr_phantoms_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_sample(mvr_sample, cvr_sample)\n",
    "p_max = find_p_values(contests, all_assertions, mvr_sample, cvr_sample, manifest_type, \\\n",
    "                      risk_function= risk_fn)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, N_cards, n_cvrs, \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {
    "6cab9cab294247839758fa9e8d64d122": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "b7b0321f834d45ebb1bdc036fba7a916": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
